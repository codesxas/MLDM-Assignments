{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDM lab#10",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufqxI496yOqY",
        "colab_type": "text"
      },
      "source": [
        "**Problem statement 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl3yiqTD9sfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_PmUj7oyRe3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "712d660b-5e1f-4b4f-d284-372826f93a08"
      },
      "source": [
        "np.random.seed(123)\n",
        "\n",
        "allwalks = []\n",
        "\n",
        "for i in range(250):\n",
        "    randwalk = [0]\n",
        "    for x in range(100):\n",
        "        step = randwalk[-1]\n",
        "        dice = np.random.randint(1,7)\n",
        "        if dice <= 2 :\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice<=5:\n",
        "            step += 1\n",
        "\n",
        "        else:\n",
        "            step = step + np.random.randint(1,7)\n",
        "        \n",
        "    print(step)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "5\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "6\n",
            "0\n",
            "0\n",
            "1\n",
            "6\n",
            "0\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "6\n",
            "1\n",
            "0\n",
            "5\n",
            "1\n",
            "0\n",
            "1\n",
            "5\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "5\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "5\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "3\n",
            "3\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "6\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "3\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkK-hCK2AVL",
        "colab_type": "text"
      },
      "source": [
        "**Problem statement 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeI1Uj8g9lhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random data for multiple linear regression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReY3UU3qzgyE",
        "colab_type": "code",
        "outputId": "ff37b02a-beed-4707-8ab9-e5706001896e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "random.seed(1)\n",
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "eps = scipy.stats.norm.rvs(0, 0.25,100)\n",
        "y = 1 + (0.4 * X[0]) + eps + (0.5 * X[1]) + (0.3 * X[2]) + (0.4 * X[3])\n",
        "data_mlr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y }\n",
        "df = pd.DataFrame(data_mlr)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "#df.to_csv('file1.csv')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3         Y\n",
            "0  0.310326 -0.538983  0.522009 -0.630752  0.866218\n",
            "1  0.026933  1.005510 -1.519784  0.317596  1.772350\n",
            "2  1.454472 -1.948507  0.989502  1.673824  1.499090\n",
            "3  0.299680 -1.090324 -0.968199  0.285824  0.208772\n",
            "4  1.568637  0.042656 -0.204593  1.126121  2.364669\n",
            "          X0        X1        X2        X3         Y\n",
            "95 -0.408410  0.615359 -2.553963  1.017630  0.665650\n",
            "96  1.271942  0.739803  1.451475 -2.180999  1.384007\n",
            "97 -1.462029 -1.407781  0.657375  0.320367  0.282489\n",
            "98 -0.355275 -1.795455  0.762725 -0.701842 -0.191871\n",
            "99 -0.845194 -0.817530 -1.009229  0.328676 -0.035132\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.012668   -0.098384    0.002392    0.037210    0.993038\n",
            "std      0.984979    1.056384    0.890788    1.027167    0.826427\n",
            "min     -2.174584   -2.241255   -2.553963   -3.162631   -0.839570\n",
            "25%     -0.761235   -0.900435   -0.565406   -0.652427    0.476432\n",
            "50%     -0.013255   -0.008498   -0.023229    0.078830    1.022160\n",
            "75%      0.724811    0.740714    0.684799    0.733959    1.624228\n",
            "max      2.259437    2.192720    2.373255    2.320635    2.737757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhRfGyIbAjqB",
        "colab_type": "code",
        "outputId": "89f1552c-57b3-4a87-b2a7-50789f3bed2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# Random data for logistic regression\n",
        "\n",
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "a1 = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))/(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))))\n",
        "#print(a1)\n",
        "y1 = []\n",
        "for i in a1:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "#print(y1)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df1.head())\n",
        "print(df1.tail())\n",
        "print(df1.info())\n",
        "print(df1.describe())\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3  Y\n",
            "0  1.401957 -1.355933  1.594828 -0.749478  1\n",
            "1 -0.028443  0.594037 -0.282306  1.315282  1\n",
            "2 -0.262065 -0.633718 -0.054076 -0.785498  1\n",
            "3 -0.874858 -1.010066  0.765558 -0.558065  1\n",
            "4 -0.337952  1.498269  0.413932 -0.675617  1\n",
            "          X0        X1        X2        X3  Y\n",
            "95  1.488679 -0.205017 -0.989172  0.346556  1\n",
            "96  0.227252  0.510480  0.642715  1.009932  1\n",
            "97  0.222371 -0.404990 -0.309676 -1.455182  1\n",
            "98 -1.468875 -2.338533 -0.549930 -1.449617  0\n",
            "99  0.071898 -0.166012  0.201322  0.086252  1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.048892    0.031605    0.022196    0.021526    0.910000\n",
            "std      0.922258    1.095960    0.896893    0.908970    0.287623\n",
            "min     -2.538611   -2.338533   -2.145315   -2.376022    0.000000\n",
            "25%     -0.569378   -0.791644   -0.583555   -0.655579    1.000000\n",
            "50%     -0.025219   -0.113815    0.043722    0.086263    1.000000\n",
            "75%      0.715849    0.769525    0.695305    0.715316    1.000000\n",
            "max      1.871004    3.107332    2.707045    2.240492    1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j_SGQjgfc5s",
        "colab_type": "code",
        "outputId": "a7ec2192-72be-420f-c91d-11ed4961d49b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        }
      },
      "source": [
        "# Random data for K means clustering\n",
        "\n",
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmeans)\n",
        "print(df3.head())\n",
        "print(df3.tail())\n",
        "print(df3.info())\n",
        "print(df3.describe())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1\n",
            "0 -0.910291 -1.107965\n",
            "1 -0.452878 -0.363909\n",
            "2 -0.881600 -1.350616\n",
            "3 -1.988249 -1.274137\n",
            "4 -0.467966 -1.237406\n",
            "          X0        X1\n",
            "95  1.843253  1.878599\n",
            "96  2.237738  1.420158\n",
            "97  1.815515  2.692840\n",
            "98  1.146802  2.445512\n",
            "99  1.311867  1.419553\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 1.7 KB\n",
            "None\n",
            "               X0          X1\n",
            "count  100.000000  100.000000\n",
            "mean     0.592209    0.475260\n",
            "std      1.600742    1.487374\n",
            "min     -1.988249   -1.974740\n",
            "25%     -0.891426   -0.969846\n",
            "50%      0.465980    0.540791\n",
            "75%      2.123728    1.843550\n",
            "max      2.970304    2.930933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1dxQMGDYIOq",
        "colab_type": "text"
      },
      "source": [
        "**Problem statement - 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa3knLkqGTZv",
        "colab_type": "code",
        "outputId": "a68ad89c-72f7-4dea-e823-2b6bcf5c337d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Linear Regression using gradient descent\n",
        "\n",
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08297726333408594 0.18006939723867305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkzDhVrZZ6rq",
        "colab_type": "code",
        "outputId": "68c6d449-e442-4064-c970-821e4c237d08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Logistic regression using Gradient descent\n",
        "\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.30250249211695207\n",
            "0.30246767315723116\n",
            "0.30243335732066357\n",
            "0.3023995359985447\n",
            "0.3023662007767267\n",
            "0.30233334342983526\n",
            "0.3023009559156906\n",
            "0.3022690303699237\n",
            "0.3022375591007821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h29KsbGVpGYF",
        "colab_type": "code",
        "outputId": "17960118-ee19-4307-e0c9-ffaad260ef66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Linear Regression using L1 regularization\n",
        "\n",
        "X = df.iloc[:,0].values\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0738712823591653 0.18008044130900397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQRD15PuqENj",
        "colab_type": "code",
        "outputId": "96d4ba80-c32e-49f9-a53d-44210c4f6440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Linear Regression using L2 regularization\n",
        "\n",
        "X = df.iloc[:,0].values\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08257998381739863 0.1800697210778034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqr8pUh8rJ0A",
        "colab_type": "code",
        "outputId": "24ace606-de2f-41bd-fab4-c52f81969df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Logistic regression using L1 regularization\n",
        "\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "-0.0957178147843501\n",
            "-0.49126928267553843\n",
            "-0.8838759664840703\n",
            "-1.2735829336825866\n",
            "-1.660434584454674\n",
            "-2.044474635211784\n",
            "-2.4257461061958714\n",
            "-2.804291312728332\n",
            "-3.1801518596965117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYOUM896rrsz",
        "colab_type": "code",
        "outputId": "c689be39-9e05-4ee2-ef18-7602be235a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Logistic regression using L2 regularization\n",
        "\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.30253765266491595\n",
            "0.30260591111172064\n",
            "0.30273910226152506\n",
            "0.30293387149915413\n",
            "0.3031870022514592\n",
            "0.30349541047524015\n",
            "0.30385613937861167\n",
            "0.30426635436466415\n",
            "0.30472333818688496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdkxTDkgEMDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# K Means Clustering Algorithm\n",
        "\n",
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"b\",\"c\",\"g\",\"r\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpLrjR_OiXo3",
        "colab_type": "code",
        "outputId": "751f2e58-f6b9-44f5-b261-fd765224e3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"4\", color=color, s=150, linewidths=5)\n",
        "        "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15.664930630940857\n",
            "89.34592331504277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ArGImKtseys",
        "colab_type": "text"
      },
      "source": [
        "**Problem Statement - 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz42F7jnsjQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Linear Regression from scratch using OOPS\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) # Type: Numpy float.\n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "\n",
        "if __name__ == \"__main__\": main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IX47f-btjwf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljHZlX41txID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression from scratch using OOPS\n",
        "\n",
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuBU7YY_t90Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# K Means from scratch using OOPS\n",
        "\n",
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
